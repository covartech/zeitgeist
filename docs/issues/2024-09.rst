2024-09
=======

Featured
--------
`MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction <https://arxiv.org/pdf/2407.21635>`_
    Uses relation transformers to do multi-agent tracking in basketball data.  This kind of makes sense since tracking involves sequences and transformers are good at that.

`Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing <https://arxiv.org/pdf/2404.01223>`_
    Combines 3D Gaussian splats with VLMS and physics-based models to enable text-based scened decomposition and to simulate physics-based dynamics in a 3D Gaussian splat.  Duct-tapes a whole bunch of models together to get to a cool looking result

`Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters <https://arxiv.org/pdf/2408.03314>`_
    Deepmind investigates how best to use a finite amount of test-time compute to get an LLM to give the best answer.  Results are nuanced and the paper seems worth reading.

`Collaborative Vision-Text Representation Optimizing for Open-Vocabulary Segmentation <https://arxiv.org/pdf/2408.00744>`_
    Does some fancy footwork to turn CLIP models into something that can more or less accurately handle the open-vocabulary segmentation task.  Results seem impresive.

`SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code <https://arxiv.org/pdf/2403.01248>`_
    Google release a new LLM agent which can take natural language desriptions of a scene, generate Python scripts to render them in blender, and then iteratively refine the rendered scene.  Could be useful for some of our synthetic data generation.

`Self-Taught Evaluators <https://arxiv.org/pdf/2408.02666>`_
    From META FAIR.  Looks to improve evaluators using only synthetic data - no human labelling, no RLHF.  This sounds crazy, but training a judge in this way, without any human-labelled data, and using it to make Lamma 3 better actually made Llama 3 substantially better.

LLMs
----
`Large Language Monkeys: Scaling Inference Compute with Repeated Sampling <https://arxiv.org/pdf/2407.21787>`_
    Generating accurate answers is hard, but verifying an answer is (sometimes) easy.  If you are living in a world where verifying an answer is easy, you can have an LLM generate a ton of answers and find th correct one.  Greatly improves performance.

`LLM Critics Help Catch LLM Bugs <https://arxiv.org/pdf/2407.00215>`_
    OpenAI proposes a new training method for LLMs to replace RLHF - use other LLMs to help grade the output of an LLM in a training process. Not directly applicable for us unless we want to train an LLM from scratch, but another paper using the idea of "generate some stuff with an LLM and then evaluate for downstream use" which seems to work well and might be relevant.

`SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code <https://arxiv.org/pdf/2403.01248>`_
    Google release a new LLM agent which can take natural language desriptions of a scene, generate Python scripts to render them in blender, and then iteratively refine the rendered scene.  Could be useful for some of our synthetic data generation.

`Self-Taught Evaluators <https://arxiv.org/pdf/2408.02666>`_
    From META FAIR.  Looks to improve evaluators using only synthetic data - no human labelling, no RLHF.  This sounds crazy, but training a judge in this way, without any human-labelled data, and using it to make Lamma 3 better actually made Llama 3 substantially better.

`Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters <https://arxiv.org/pdf/2408.03314>`_
    Deepmind investigates how best to use a finite amount of test-time compute to get an LLM to give the best answer.  Results are nuanced and the paper seems worth reading.

VLMs
----

Doctrinaire
-----------
`MESHANYTHING V2: ARTIST-CREATED MESH GENERATION WITH ADJACENT MESH TOKENIZATION <https://arxiv.org/pdf/2408.02555>`_
    A model which takes "anything" (point clouds, Gaussian Splats, images, text, etc) and generates 3D meshes of the described object.  Could be useful.

Autonomy
--------
`NOLO: Navigate Only Look Once <https://arxiv.org/pdf/2408.01384>`_
    Develops a transformer model to control navigation on a drone based on input video/images.

Reinforcement Learning
----------------------

Fusion
------

Tracking
--------
`MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction <https://arxiv.org/pdf/2407.21635>`_
    Uses relation transformers to do multi-agent tracking in basketball data.  This kind of makes sense since tracking involves sequences and transformers are good at that.

Gaussian Splatting
------------------
`Feature Splatting: Language-Driven Physics-Based Scene Synthesis and Editing <https://arxiv.org/pdf/2404.01223>`_
    Combines 3D Gaussian splats with VLMS and physics-based models to enable text-based scened decomposition and to simulate physics-based dynamics in a 3D Gaussian splat.  Duct-tapes a whole bunch of models together to get to a cool looking result

Gotta Go Fast
-------------
`CAS-ViT: Convolutional Additive Self-attention Vision Transformers for Efficient Mobile Applications <https://arxiv.org/pdf/2408.03703>`_
    How to put vision transformers on an iPhone.  Hilariously, they cite a paper from 2009 showing vision transformer results?? This must be a typo?

Theory
------
`Disentangling Dense Embeddings with Sparse Autoencoders <https://arxiv.org/pdf/2408.00657>`_
    If you have dense embeddings, you can hit them with a sparse autoencoder and have sparse embeddings that maintain semantic fidelity.  Feels like there is something useful here, but can't quite put my finger on what.

`Autoencoders in Function Space <https://arxiv.org/pdf/2408.01362>`_
    Develops a variational autoencoder which functions directly on function space.  The imagined applications included computer vision, with image pixels being viewed as a pixelization of a functional space. Shows some promise on inpainting/superresolution problems.  Very theoretical, though

`Pre-training and in-context learning IS Bayesian inference a la De Finetti <https://arxiv.org/pdf/2408.03307>`_
    A very funny paper that argues pre-training and in-context learning is Bayesian inference because of De Finetti's theorem.  Not useful, but worth it for the comedy.

Applications
------------

New LLMs
--------
`Smaller, Safer, More Transparent: Advancing Responsible AI with Gemma <https://developers.googleblog.com/en/smaller-safer-more-transparent-advancing-responsible-ai-with-gemma/>`_
    Google adds three new additions to the Gemma 2B family.  They claim its the best thing on the market, etc etc.  `Lab report <https://arxiv.org/pdf/2408.00118>`_
    
Lunch and Learn
---------------
2024-08-06
    `Large Language Monkeys: Scaling Inference Compute with Repeated Sampling <https://arxiv.org/pdf/2407.21787>`_
    Generating accurate answers is hard, but verifying an answer is (sometimes) easy.  If you are living in a world where verifying an answer is easy, you can have an LLM generate a ton of answers and find th correct one.  Greatly improves performance.
