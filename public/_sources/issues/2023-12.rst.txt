2023-12
=======

`Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine <https://arxiv.org/abs/2311.16452>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
They say yes. GPT4 is great. All bow to OpenAI.

------------

`Toy Models of Superposition <https://transformer-circuits.pub/2022/toy_model/index.html>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Individual neurons in networks are not exclusively a sparse encoding of visual features. They form geometric shapes and can use (for example) 2 features to encode more than 2 concepts, but making angular patterns.

`See Also <https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand>`_

------------

`BirdNet <https://github.com/kahst/BirdNET-Analyzer>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
If you need to detection and classification of "sounds" or timeseries like things, we should look at how cornel does this for bird sounds.

------------

`Exponentially Faster Language Modeling <https://arxiv.org/abs/2311.10770>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A bit theoretical, "Fast Feed Foward Network". Nothing to see here, but potential buzzword that could catch on.

------------

`Don't Say What You Don't Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search <https://arxiv.org/abs/2203.08436>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    We analyze the connection between hallucinations and training data, and find evidence that models hallucinate because they train on target summaries that are unsupported by the source. Based on our findings, we present PINOCCHIO, a new decoding method that improves the consistency of a transformer-based abstractive summarizer by constraining beam search to avoid hallucinations. 

Miles this is probably for you.

------------

`Accelerating 3D Deep Learning with PyTorch3D <https://arxiv.org/abs/2007.08501>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Of interest to potentially change how we do model matching. Mostly for TA2 folks, but also Miles.

------------

`Estimation of NIIRS, for High Resolution Satellite Images, Using the Simplified GIQE <https://web.archive.org/web/20170202122447/https://www.ijircce.com/upload/2016/may/47_Estimation.pdf>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Has the formula relating GSD and image quality to NIIRS. Patrick we should have this in our hearts. Pete and Dima this could be a way to describe "effective pixels on target" but maybe not.

------------


`Supersizing Transformers: Going Beyond RAG with Extended minds for LLMs <https://blog.normalcomputing.ai/posts/2023-09-12-supersizing-transformers/supersizing-transformers.html>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A bunch of people are trying to adapt LLMs to put the RAG inside the LLM. This is a company doing something a little interesting. A direction to keep an eye on.

------------

`Language Models can be Logical Solvers <https://arxiv.org/abs/2311.06158>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
LLM to logic syntax, solve. Fine tuned to hell so it doesn't make logic language errors. There is something here, but is logic the right platform or DB queries?

------------

`Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild <https://arxiv.org/abs/2311.06237>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Worst title of the month award for sure.

People are mean to LLMs. Let's interview them. Then it turns into a think piece. Not for us but interesting that this type of research exists.

------------

`LLMs cannot find reasoning errors, but can correct them! <https://arxiv.org/abs/2311.08516>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Finding mistakes is hard and unsolved. 
Fixing mistakes when pointed out is doable.

------------

`Orca: Progressive Learning from Complex Explanation Traces of GPT-4 <https://arxiv.org/abs/2306.02707>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Train a smaller model on GPT4 output. It can do the "reasoning" in much fewer weights. This is the first version.
Miles and Sanika this should ring bells.

------------

`Orca 2: Teaching Small Language Models How to Reason <https://arxiv.org/abs/2311.11045>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
They continue with this idea and try to make it better with different solution approaches.
Things to learn here. 

------------

`Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading <https://arxiv.org/abs/2310.05029>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Iteratively summarizing and asking for conclusions, is a way to manage the context limit. Then you also prompt for a next step. Combine this with multiple solutions (branches) and build a tree.

Interesting idea we could explore.

------------

`The 'eu' in eucatastrophe â€“ Why SciPy builds for Python 3.12 on Windows are a minor miracle <https://labs.quansight.org/blog/building-scipy-with-flang>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
There is a group of us who have thought about build infrastructure for python packages a good bit. This is a twisting tail of how hard it is to make something appear easy to use.

This covers ground from why conda exists to how much of a pain life is for projects without setup.py and distutils.

I didn't completely grok it all, but one of us should. Griffin? Adam? Both?

    Depending on where you draw the line, hundreds or even thousands of person years of effort went into the ingredients that were necessary for us to achieve the final result 

------------

`ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up? <https://arxiv.org/abs/2311.16989>`_
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
It depends on the task. Sometimes yes, sometimes not yet but trends are promising.
