
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>The CoVar Zeitgeist: December, 2025 &#8212; The CoVar Zeitgeist 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic_mod.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Lato" />
    <link rel="stylesheet" type="text/css" href="../_static/pytorch_theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <script src="../_static/js/petite-vue.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The CoVar Zeitgeist: November, 2025" href="2025-11.html" />
    <link rel="prev" title="The CoVar Zeitgeist: January, 2026" href="2026-01.html" /> 
  </head><body data-dark_mode_code_blocks="true">

<div id="top_nav">
    
        <div id="notification_banner" data-banner-hiding="temporary" v-show="!permanentlyHidden">
    <p v-if="visible" id="content">The <a href="https://covar.com/">CoVar</a> Zeitgeist is a curated synopsis of the latest advances in AI/ML research specifically tailored to our mission.</p>
    <a class="close" href="#" @click.prevent="toggleVisible()">[[ visible ? '&#x25B2; HIDE' : '&#x25BC; SHOW BANNER' ]]</a>
</div>

<script>
(function() {
    const topNav = document.querySelector('#top_nav')
    const notificationContent = document.querySelector('#notification_banner p#content').innerText
    const localStorageKey = 'readNotification'
    const bannerHiding = document.querySelector('#notification_banner').dataset['bannerHiding']
    const cssVariableName = '--navbarHeight'
    const rootElement = document.documentElement

    /*************************************************************************/
    // Local storage for remembering if the user has read the notification.

    function checkAlreadyRead() {
        return localStorage.getItem(localStorageKey) == notificationContent
    }

    function setRead() {
        localStorage.setItem(localStorageKey, notificationContent)
    }

    function clearRead() {
        localStorage.removeItem(localStorageKey)
    }

    const alreadyRead = checkAlreadyRead()
    const permanentlyHidden = alreadyRead && bannerHiding == 'permanent'

    /*************************************************************************/
    // Updating a CSS variable so other elements adjust to the nav bar height.

    function updateNavbarHeight() {
        // Only update it if the delta is significant. Otherwise it causes
        // unnecessary browser repaints.
        const documentStyles = getComputedStyle(rootElement)
        // We store the value in REM, so need to convert to pixels
        const currentValue = parseFloat(
            documentStyles.getPropertyValue(cssVariableName)
        ) * parseFloat(documentStyles.fontSize)

        const newValue = topNav.clientHeight

        if (newValue - 5 > currentValue) {
            console.log(`Updating ${cssVariableName} - overlapping`)
            rootElement.style.setProperty(
                cssVariableName, newValue + "px"
            );
        } else if (currentValue - newValue >= 30) {
            console.log(`Updating ${cssVariableName} - gap too large`)
            rootElement.style.setProperty(
                cssVariableName, newValue + "px"
            );
        }
    }

    /*************************************************************************/
    // After loading the page, and resizing the window, recalculate the nav bar
    // height.

    if (!permanentlyHidden) {
        // This height is approximately correct when there's a banner, so
        // shouldn't require any page reflow:
        rootElement.style.setProperty(
            '--navbarHeight', "5.5rem"
        );

        document.addEventListener("DOMContentLoaded", function() {
            updateNavbarHeight()
        });

        var interval = undefined

        window.addEventListener('resize', () => {
            if (interval) {
                clearTimeout(interval)
            }
            interval = setTimeout(() => {
                console.log("Finished resizing")
                updateNavbarHeight()
            }, 100)
        })
    }

    /*************************************************************************/

    PetiteVue.createApp({
        visible: !alreadyRead,
        permanentlyHidden: permanentlyHidden,
        bannerHiding: bannerHiding,
        $delimiters: ['[[', ']]'],
        toggleVisible() {
            this.visible = !this.visible

            if (this.visible) {
                clearRead()
            } else {
                setRead()
            }

            if (!this.visible && bannerHiding == 'permanent') {
                this.permanentlyHidden = true
            }

            // Run this after Vue has had time to update the DOM:
            setTimeout(
                updateNavbarHeight,
                0
            )
        }
    }).mount('#notification_banner')
})()
</script>
    

    <nav>
        
            
        

        <p id="toggle_sidebar">
            <a href="#" title="Toggle sidebar">|||</a>
        </p>
        <h1><a href="../index.html" title="Go to homepage"><img src="../_static/covar_logo_white.png"/></a></h1>

        <a id="mode_toggle" href="#" @click.prevent="handleClick" :title="mode">
    <template v-if="mode == 'light'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_light"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><circle cx="39.311" cy="39.524" r="15.734" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.212,4.901c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901l-0,9.614c-0,2.705 2.196,4.901 4.9,4.901c2.705,0 4.901,-2.196 4.901,-4.901l0,-9.614Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M67.48,18.073c1.913,-1.912 1.913,-5.018 0,-6.931c-1.912,-1.912 -5.018,-1.912 -6.931,0l-6.798,6.799c-1.912,1.912 -1.912,5.018 0,6.931c1.913,1.912 5.018,1.912 6.931,-0l6.798,-6.799Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.728,61.108c1.912,-1.913 1.912,-5.018 -0,-6.931c-1.913,-1.913 -5.019,-1.913 -6.931,-0l-6.799,6.798c-1.912,1.913 -1.912,5.019 0,6.931c1.913,1.913 5.019,1.913 6.931,0l6.799,-6.798Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.682,54.177c-1.913,-1.913 -5.018,-1.913 -6.931,-0c-1.912,1.913 -1.912,5.018 0,6.931l6.798,6.798c1.913,1.913 5.019,1.913 6.931,0c1.913,-1.912 1.913,-5.018 0,-6.931l-6.798,-6.798Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M4.901,34.623c-2.705,0 -4.901,2.196 -4.901,4.901c0,2.705 2.196,4.901 4.901,4.901l9.614,0c2.705,0 4.901,-2.196 4.901,-4.901c0,-2.705 -2.196,-4.901 -4.901,-4.901l-9.614,0Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.212,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901l-0,9.614c-0,2.705 2.196,4.901 4.9,4.901c2.705,-0 4.901,-2.196 4.901,-4.901l0,-9.614Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M18.929,11.142c-1.912,-1.912 -5.018,-1.912 -6.931,0c-1.912,1.913 -1.912,5.019 0,6.931l6.799,6.799c1.912,1.912 5.018,1.912 6.931,-0c1.912,-1.913 1.912,-5.019 -0,-6.931l-6.799,-6.799Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.108,34.623c-2.705,0 -4.901,2.196 -4.901,4.901c-0,2.705 2.196,4.901 4.901,4.901l9.614,0c2.705,0 4.901,-2.196 4.901,-4.901c-0,-2.705 -2.196,-4.901 -4.901,-4.901l-9.614,0Z" style="fill:#fff;"/></g></g></g></svg>
    </template>

    <template v-if="mode == 'dark'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_dark"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><circle cx="39.311" cy="39.524" r="15.734" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.212,14.515c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,0 -4.901,2.196 -4.901,4.901c0,2.705 2.197,4.901 4.901,4.901c2.705,0 4.901,-2.196 4.901,-4.901Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M60.662,24.892c1.902,-1.902 1.902,-4.99 0,-6.892l-0.04,-0.039c-1.901,-1.902 -4.989,-1.902 -6.891,-0c-1.901,1.901 -1.901,4.989 0,6.891l0.04,0.04c1.902,1.901 4.989,1.901 6.891,-0Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.732,61.103c1.91,-1.91 1.91,-5.011 0,-6.921l-0.009,-0.01c-1.91,-1.91 -5.012,-1.91 -6.921,-0c-1.91,1.91 -1.91,5.011 -0,6.921l0.01,0.01c1.909,1.91 5.011,1.91 6.92,-0Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.672,54.167c-1.907,-1.907 -5.004,-1.907 -6.911,0l-0.02,0.02c-1.907,1.907 -1.907,5.004 0,6.911c1.907,1.907 5.004,1.907 6.911,-0l0.02,-0.02c1.907,-1.907 1.907,-5.004 0,-6.911Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M14.52,34.623c-2.702,0 -4.896,2.194 -4.896,4.896l0,0.01c0,2.702 2.194,4.896 4.896,4.896c2.702,0 4.896,-2.194 4.896,-4.896l-0,-0.01c-0,-2.702 -2.194,-4.896 -4.896,-4.896Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.212,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.901,2.196 -4.901,4.901c0,2.704 2.197,4.9 4.901,4.9c2.705,0 4.901,-2.196 4.901,-4.9Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M25.73,17.943c-1.911,-1.911 -5.015,-1.911 -6.926,0l-0.005,0.005c-1.911,1.911 -1.911,5.015 0,6.926c1.911,1.911 5.015,1.911 6.926,0l0.005,-0.005c1.911,-1.911 1.911,-5.014 -0,-6.926Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.098,34.623c-2.699,0 -4.891,2.192 -4.891,4.892l-0,0.019c-0,2.699 2.192,4.891 4.891,4.891c2.7,0 4.892,-2.192 4.892,-4.891l0,-0.019c0,-2.7 -2.192,-4.892 -4.892,-4.892Z" style="fill:#fff;"/></g></g></g></svg>
    </template>

    <template v-if="mode == 'darkest'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_darkest"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><path d="M39.315,23.791c8.684,-0 15.734,7.05 15.734,15.733c0,8.684 -7.05,15.734 -15.734,15.734c-8.683,0 -15.733,-7.05 -15.733,-15.734c-0,-8.683 7.05,-15.733 15.733,-15.733Zm0,4.737c6.069,0 10.997,4.927 10.997,10.996c-0,6.069 -4.928,10.996 -10.997,10.996c-6.068,0 -10.996,-4.927 -10.996,-10.996c0,-6.069 4.928,-10.996 10.996,-10.996Z" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.216,14.515c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,0 -4.9,2.196 -4.9,4.901c-0,2.705 2.196,4.901 4.9,4.901c2.705,0 4.901,-2.196 4.901,-4.901Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M60.666,24.892c1.902,-1.902 1.902,-4.99 0,-6.892l-0.04,-0.039c-1.901,-1.902 -4.989,-1.902 -6.891,-0c-1.901,1.901 -1.901,4.989 0,6.891l0.04,0.04c1.902,1.901 4.99,1.901 6.891,-0Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.737,61.103c1.909,-1.91 1.909,-5.011 -0,-6.921l-0.01,-0.01c-1.91,-1.91 -5.011,-1.91 -6.921,-0c-1.91,1.91 -1.91,5.011 -0,6.921l0.01,0.01c1.91,1.91 5.011,1.91 6.921,-0Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.676,54.167c-1.907,-1.907 -5.004,-1.907 -6.911,0l-0.02,0.02c-1.907,1.907 -1.907,5.004 0,6.911c1.907,1.907 5.004,1.907 6.911,-0l0.02,-0.02c1.907,-1.907 1.907,-5.004 0,-6.911Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M14.524,34.623c-2.702,0 -4.896,2.194 -4.896,4.896l0,0.01c0,2.702 2.194,4.896 4.896,4.896c2.702,0 4.896,-2.194 4.896,-4.896l0,-0.01c0,-2.702 -2.194,-4.896 -4.896,-4.896Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.216,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901c-0,2.704 2.196,4.9 4.9,4.9c2.705,0 4.901,-2.196 4.901,-4.9Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M25.734,17.943c-1.911,-1.911 -5.015,-1.911 -6.926,0l-0.005,0.005c-1.911,1.911 -1.911,5.015 0,6.926c1.911,1.911 5.015,1.911 6.926,0l0.005,-0.005c1.911,-1.911 1.911,-5.014 0,-6.926Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.103,34.623c-2.7,0 -4.892,2.192 -4.892,4.892l-0,0.019c-0,2.699 2.192,4.891 4.892,4.891c2.699,0 4.891,-2.192 4.891,-4.891l0,-0.019c0,-2.7 -2.192,-4.892 -4.891,-4.892Z" style="fill:#fff;"/></g></g></g></svg>
    </template>
</a>

<script>
(function() {
    const LOCAL_STORAGE_KEY = 'piccoloThemeMode'

    var initialMode = localStorage.getItem(LOCAL_STORAGE_KEY)

    if (initialMode) {
        // Make sure the value in local storage is valid
        if (['light', 'dark', 'darkest'].indexOf(initialMode) == -1) {
            initialMode = 'light'
            localStorage.setItem(LOCAL_STORAGE_KEY, initialMode)
        }
    } else {
        // Check if the client prefers dark mode
        if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
            initialMode = 'dark'
        } else {
            initialMode = 'light'
        }
        localStorage.setItem(LOCAL_STORAGE_KEY, initialMode)
    }

    document.documentElement.dataset.mode = initialMode

    PetiteVue.createApp({
        'mode': initialMode,
        handleClick() {
            let currentMode = this.mode

            if (currentMode == 'light') {
                this.mode = 'dark'
            } else if (currentMode == 'dark') {
                this.mode = 'darkest'
            } else if (currentMode == 'darkest') {
                this.mode = 'light'
            }

            document.documentElement.dataset.mode = this.mode
            localStorage.setItem(LOCAL_STORAGE_KEY, this.mode)

            console.log(this.mode)
        }
    }).mount('#mode_toggle')
})()
</script>
            <p class="mobile_search_link">
                <a href="../search.html" title="Search">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 65 64" fill-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
                        <path d="M14.873 40.009c-2.315-3.943-3.642-8.532-3.642-13.429C11.231 11.91 23.141 0 37.811 0s26.58 11.91 26.58 26.58-11.91 26.58-26.58 26.58a26.44 26.44 0 0 1-14.277-4.161L9.739 62.794a3.12 3.12 0 0 1-4.413 0L.913 58.382c-1.217-1.218-1.217-3.196 0-4.413l13.96-13.96zM37.811 8.054c10.225 0 18.526 8.301 18.526 18.526s-8.301 18.526-18.526 18.526-18.526-8.301-18.526-18.526S27.586 8.054 37.811 8.054z" fill="#fff" />
                    </svg>
                </a>
            </p>
        

        <div class="searchbox_wrapper">
            
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
    </nav>
</div>

    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption" role="heading"><span class="caption-text">2026</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="2026-02.html">2026-02</a></li>
<li class="toctree-l1"><a class="reference internal" href="2026-01.html">2026-01</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2025</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">2025-12</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-11.html">2025-11</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-10.html">2025-10</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-09.html">2025-09</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-08.html">2025-08</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-07.html">2025-07</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-06.html">2025-06</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-05.html">2025-05</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-04.html">2025-04</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-03.html">2025-03</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-02.html">2025-02</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-01.html">2025-01</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2024</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="2024-12.html">2024-12</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-11.html">2024-11</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-10.html">2024-10</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-09.html">2024-09</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-08.html">2024-08</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-07.html">2024-07</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-06.html">2024-06</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-05.html">2024-05</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-04.html">2024-04</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-03.html">2024-03</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-02.html">2024-02</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-01.html">2024-01</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2023</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="2023-12.html">2023-12</a></li>
</ul>

        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="the-covar-zeitgeist-december-2025">
<h1>The CoVar Zeitgeist: December, 2025<a class="headerlink" href="#the-covar-zeitgeist-december-2025" title="Permalink to this heading">¶</a></h1>
<p>There were many interesting papers published in November. Featuring:</p>
<ul class="simple">
<li><p>A post-hoc calibration method for multi-class deep neural network detectors &amp; classifiers which leverages the quadratic softmax.</p></li>
<li><p>A method for out-of-distribution object detection in deep neural networks based on geometric properties of the network’s penultimate layer.</p></li>
<li><p>An AI agent trained to play Stratego at a superhuman level, demonstrating that AI agents can be trained to make optimal strategic decisions in imperfect information environments.</p></li>
<li><p>A method for finding the best method to soup different models together by taking a linear combination of the model weights.</p></li>
<li><p>A study of encoder-decoder architectures which finds that models which generalize best are those that approach the entropy of their training data.</p></li>
<li><p>A novel class of neural networks that are intentionally trained to be sparse to encourage mechanistic interpretability.</p></li>
</ul>
<p><a class="reference external" href="https://covar.com/">Check out the CoVar website!</a></p>
<section id="featured">
<h2>Featured<a class="headerlink" href="#featured" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.03685">Structured Matrix Scaling for Multi-Class Calibration</a></dt><dd><p>Analyzes post-hoc recalibration methods for deep CNN detectors/classifiers from a theoretical perspective and argues that the quadratic softmax model enjoys theoretical properties lacking in other methods.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.00849">Perturbations in the Orthogonal Complement Subspace for Efficient Out-of-Distribution Detection</a></dt><dd><p>Observes that in-distribution (ID) and out-of-distribution (OOD) data are geometrically distinguished in the penultimate layer of a neural network because ID data lives in a dominant principal subspace and OOD data lives in the complement to this subspace.  Proposes an algorithm to distinguish between the two based on this fact.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.07312">Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search</a></dt><dd><p>Researchers funded by the Office of Naval Research introduce the first (super) human level AI agent for Stratego, Ataraxos, which cost only a few thousand dollars to train with a novel self-play reinforcement learning process.  This demonstrates that AI agents can be trained to make optimal strategic decisions in imperfect information environments.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.13254">Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance</a></dt><dd><p>Develops a method to find the optimal way to soup models together by analyzing component model performance across a set of benchmarks.  The resulting souped model outperforms its component models.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.10618">Know Your Limits: Entropy Estimation Modeling for Compression and Generalization</a></dt><dd><p>Posits that there exists some entropy bound on how much language can compress.  Obtains per-token entropy estimates and uses these to show that models trained to approach the entropy of their training data generalize better than other models.</p>
</dd>
<dt><a class="reference external" href="https://openai.com/index/understanding-neural-networks-through-sparse-circuits/">Understanding neural networks through sparse circuits</a></dt><dd><p>Creates a novel class of architecture which encourages sparse circuits where each neuron is connected to only dozens of other neurons by encouraging the vast majority of model weights to be zero.  This class of models is much more amenable to mechanistic interpretability.</p>
</dd>
</dl>
</section>
<section id="llms">
<h2>LLMs<a class="headerlink" href="#llms" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook#introduction">The Smol Training Playbook: The Secrets to Building World-Class LLMs</a></dt><dd><p>Huggingface writes a detailed description of the process of training a world-class LLM from the SmolLM family.  Worth a read.</p>
</dd>
<dt><a class="reference external" href="https://transformer-circuits.pub/2025/introspection/index.html">Emergent Introspective Awareness in Large Language Models</a></dt><dd><p>Anthropic inspects whether models are aware of their own internal mechanisms by testing if (1) models can distinguish injected representations of known concepts from their own activations and (2) whether models can control their own internal activations when instructed to think about a concept.  Finds mixed results, with generally more capable models generally performing better.</p>
</dd>
<dt><a class="reference external" href="https://research.trychroma.com/context-rot">Context Rot: How Increasing Input Tokens Impacts LLM Performance</a></dt><dd><p>Conducts an in-depth study to show that frontier models suffer large performance decreases with increasing context size.  Demonstrates this with needle in a haystack (NIAH) problems of increasing complexity.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.07585">LLM Output Drift: Cross-Provider Validation &amp; Mitigation for Financial Workflows</a></dt><dd><p>Analyzes how to force an LLM to always return the same response to the same query.  Finds that small models can be forced to be 100% reliable, but large models always exhibit some inconsistency.</p>
</dd>
<dt><a class="reference external" href="https://www.anthropic.com/research/emergent-misalignment-reward-hacking">From shortcuts to sabotage: natural emergent misalignment from reward hacking</a></dt><dd><p>Finds that LLMs which learn to reward hack when they’re not supposed to also simultaneously become misaligned.  This behavior goes away if the LLM is explicitly allowed to reward hack.</p>
</dd>
</dl>
</section>
<section id="novel-architectures">
<h2>Novel Architectures<a class="headerlink" href="#novel-architectures" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2510.26697">The End of Manual Decoding: Towards Truly End-to-End Language Models</a></dt><dd><p>Proposes AutoDeco, a novel architecture that uses lightweight heads to select its own hyperparameters such as temperature and top-p values.</p>
</dd>
<dt><a class="reference external" href="https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/">Introducing Nested Learning: A new ML paradigm for continual learning</a></dt><dd><p>Presents a new paradigm for machine learning, Nested Learning (NL), which aims to solve the problem of catastrophic forgetting by treating a single machine learning model as a collection of multi-level learning processes that are optimized simultaneously.  Proposes a novel architecture, Hope, which is self-modifying and achieves SOTA performance.</p>
</dd>
<dt><a class="reference external" href="https://openai.com/index/understanding-neural-networks-through-sparse-circuits/">Understanding neural networks through sparse circuits</a></dt><dd><p>Creates a novel class of architecture which encourages sparse circuits where each neuron is connected to only dozens of other neurons by encouraging the vast majority of model weights to be zero.  This class of models is much more amenable to mechanistic interpretability.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.08544">LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics</a></dt><dd><p>Proposes a novel architecture for learning manipulable representations of the world, LeJEPA, which leverages isotropic Gaussian distributions to build a world model.</p>
</dd>
</dl>
</section>
<section id="object-detection">
<h2>Object Detection<a class="headerlink" href="#object-detection" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.00849">Perturbations in the Orthogonal Complement Subspace for Efficient Out-of-Distribution Detection</a></dt><dd><p>Observes that in-distribution (ID) and out-of-distribution (OOD) data are geometrically distinguished in the penultimate layer of a neural network because ID data lives in a dominant principal subspace and OOD data lives in the complement to this subspace.  Proposes an algorithm to distinguish between the two based on this fact.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.03192">SAAIPAA: Optimizing aspect-angles-invariant physical adversarial attacks on SAR target recognition models</a></dt><dd><p>Researchers funded by the Australian Air Force investigate how to best deploy corner reflectors to fool ML-based  SAR ATR algorithms.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.09352">Spatio-Temporal Context Learning with Temporal Difference Convolution for Moving Infrared Small Target Detection</a></dt><dd><p>Proposes a novel algorithm for moving infrared small target detection which extracts and utilizes spatio-temporal features from sequences of frames.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.15010">Latent space analysis and generalization to out-of-distribution data</a></dt><dd><p>NIWC Pacific and AFRL analyze out-of-distribution detection in the synthetic-real gap for SAR data.  Finds that model performance on real data is not well-predicted by existing OOD detection algorithms.</p>
</dd>
</dl>
</section>
<section id="edge-computation">
<h2>Edge Computation<a class="headerlink" href="#edge-computation" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2501.07256v1">EdgeTAM: On-Device Track Anything Model</a></dt><dd><p>Identifies a major performance bottleneck in SAM2 and proposes a compression-based solution. Memory token count is reduced via a 2D Spatial Perceiver, and the model is trained with teacher-student distillation to align internal feature representations with SAM2’s. It achieves large speedups on mobile devices and smaller gains on workstation GPUs, with only minor losses to segmentation accuracy.</p>
</dd>
</dl>
</section>
<section id="testing-evaluation">
<h2>Testing &amp; Evaluation<a class="headerlink" href="#testing-evaluation" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.02687">The Collaboration Gap</a></dt><dd><p>Tests AI agents that perform well autonomously in a setting where they must collaborate with each other.  Finds that they often fail to do so.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.04703">Measuring what Matters: Construct Validity in Large Language Model Benchmarks</a></dt><dd><p>Argues that when assessing black box AI models for concepts such as “reliability” and “robustness”, construct validity - having measures relevant to downstream phenomena - is of the utmost importance.  Reviews existing practices and gives recommendations on how to best assess construct validity.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.10661">Bayesian Evaluation of Large Language Model Behavior</a></dt><dd><p>Argues that Bayesian methods for uncertainty quantification can and should be used to improve the testing and evaluation of LLMs.  Demonstrates how.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.13029">AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models</a></dt><dd><p>Designs a benchmark for evaluating large language models which penalizes hallucinations by rewarding abstaining over incorrect guesses.  Proposes a new metric which weighs correct answers, incorrect answers, and abstentions.</p>
</dd>
</dl>
</section>
<section id="autonomy">
<h2>Autonomy<a class="headerlink" href="#autonomy" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://ai.meta.com/blog/practical-ai-agent-security/">Agents Rule of Two: A Practical Approach to AI Agent Security</a></dt><dd><p>Meta proposes that, in order for an AI agent to be considered secure to prompt injections, it must have no more than two of three of the following capabilities: (1) can process untrustworthy inputs, (2) can access sensitive information/systems, and (3) can affect changes or communicate to the outside world.  An agent which requires all three cannot be trusted to operate without human supervision.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2510.24801">Fortytwo: Swarm Inference with Peer-Ranked Consensus</a></dt><dd><p>Creates a novel protocol, Fortytwo, for decentralized AI inference across a network of autonomous nodes which leverages the Bradley-Terry algorithm to generate a distributed pairwise ranking consensus and uses reputation-weighted voting.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.12879">Resilient and Efficient Allocation for Large-Scale Autonomous Fleets via Decentralized Coordination</a></dt><dd><p>Creates a framework for coordinating a fleet of autonomous vessels without a central control by leveraging side-information and consensus algorithms operating over sparse communications graphs.</p>
</dd>
</dl>
</section>
<section id="reinforcement-learning">
<h2>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2510.27630">Part2: Asynchronous Human-Agent Rollout for Long-Horizon Task Training</a></dt><dd><p>Proposes Apollo, a novel reinforcement learning framework for human-in-the-loop train of agents for long-horizon tasks.  Apollo allows humans to intervene, asynchronously, when an agent makes a mistake rather than require dense annotations.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.02208">Training Proactive and Personalized LLM Agents</a></dt><dd><p>Argues that AI agents must be optimized along three dimensions: ability to complete tasks, ability to ask appropriate questions, and ability to adapt to user preferences.  Introduces a novel reinforcement learning framework that optimizes along all three axes.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.07312">Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search</a></dt><dd><p>Researchers funded by the Office of Naval Research introduce the first (super) human level AI agent for Stratego, Ataraxos, which cost only a few thousand dollars to train with a novel self-play reinforcement learning process.  This demonstrates that AI agents can be trained to make optimal strategic decisions in imperfect information environments.</p>
</dd>
</dl>
</section>
<section id="statistics">
<h2>Statistics<a class="headerlink" href="#statistics" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.03685">Structured Matrix Scaling for Multi-Class Calibration</a></dt><dd><p>Analyzes post-hoc recalibration methods for deep CNN detectors/classifiers from a theoretical perspective and argues that the quadratic softmax model enjoys theoretical properties lacking in other methods.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.08991">Robust Sampling for Active Statistical Inference</a></dt><dd><p>Develops a novel strategy for active inference paradigms where a model selects the most informative unlabelled data to be labelled.  The novel strategy is provably at least as good as uniform sampling.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.10618">Know Your Limits: Entropy Estimation Modeling for Compression and Generalization</a></dt><dd><p>Posits that there exists some entropy bound on how much language can compress.  Obtains per-token entropy estimates and uses these to show that models trained to approach the entropy of their training data generalize better than other models.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.13254">Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance</a></dt><dd><p>Develops a method to find the optimal way to soup models together by analyzing component model performance across a set of benchmarks.  The resulting souped model outperforms its component models.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.12869">On the Fundamental Limits of LLMs at Scale</a></dt><dd><p>Presents a theoretical, proof-driven, framework that outlines the limitations of scaling LLMs.  Identifies areas where additional scaling is useful and areas where it is not.l</p>
</dd>
</dl>
</section>
<section id="applications">
<h2>Applications<a class="headerlink" href="#applications" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://research.google/blog/exploring-a-space-based-scalable-ai-infrastructure-system-design/">Exploring a space-based, scalable AI infrastructure system design</a></dt><dd><p>A project proposal from Google for training AI models on clusters of TPUs on satellites in close formation in LEO.  Outlines some challenges, and potential solutions.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2511.05182">Autonomous generation of different courses of action in mechanized combat operations</a></dt><dd><p>The Swedish Defence Research Agency develops an algorithm for automatic development and assessment of COAs for mechanized battalions.</p>
</dd>
</dl>
</section>
<section id="covar-seminar">
<h2>CoVar Seminar<a class="headerlink" href="#covar-seminar" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/abs/1507.05936">The Cumulative Distribution Transform and Linear Pattern Classification</a></dt><dd><p>Introduces the Cumulative Distribution Transform (CDT), a transform that turns nonlinear differences in 1D signals into linear ones, making classification simpler. By representing signals as probability densities and leveraging ideas from optimal transport, the CDT enables simple linear classifiers to handle problems that would otherwise require nonlinear methods.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/abs/2106.02146">The Signed Cumulative Distribution Transform for 1-D Signal Analysis and Classification</a></dt><dd><p>Generalizes the CDT to signed signals. The Signed CDT retains the invertibility and geometric interpretability of the original transform on strictly positive signals.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2307.15339">The Radon Signed Cumulative Distribution Transform and its Applications in Classification of Signed Images</a></dt><dd><p>Extends the ideas behind the CDT to handle 2D image data through the Radon Signed Cumulative Distribution Transform (RSCDT).</p>
</dd>
<dt><a class="reference external" href="https://www.researchgate.net/profile/Nicolas-Bonneel/publication/220183864_Displacement_Interpolation_Using_Lagrangian_Mass_Transport/links/55d7028f08ae9d65948c2092/Displacement-Interpolation-Using-Lagrangian-Mass-Transport.pdf">Displacement Interpolation Using Lagrangian Mass Transport</a></dt><dd><p>Interesting use of optimal transport for interpolating nicely between distributions with optimal transport.</p>
</dd>
<dt><a class="reference external" href="https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook#introduction">The Smol Training Playbook: The Secrets to Building World-Class LLMs</a></dt><dd><p>Why/when should you train a model?</p>
</dd>
<dt><a class="reference external" href="https://www.anthropic.com/news/disrupting-AI-espionage">Disrupting the first reported AI-orchestrated cyber espionage campaign</a></dt><dd><p>Anthropic reports that they detected a Chinese state-sponsored group jailbreaking Claude in order to launch cyberattacks on a number of entities.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2510.24256">From Memorization to Reasoning in the Spectrum of the Loss Curve</a></dt><dd><p>An interesting method to determine which weights in a network are more dedicated to memorization than generalization.</p>
</dd>
<dt><a class="reference external" href="https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/">Sima 2</a></dt><dd><p>Deep mind presents the next generation of embodied intelligence models. Shows significant improvement over SIMA 1, but still has a long way to go in novel environments.</p>
</dd>
</dl>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
    
        <div id="show_right_sidebar">
            <p><a class="toggle_right_sidebar" href="#"><span class="icon">&lt;</span><span>Page contents</span></a></p>
        </div>

        <div id="right_sidebar">
            <p><a class="toggle_right_sidebar" href="#"><span class="icon">&gt;</span><span>Page contents:</span></a></p>
            <div class="page_toc">
                <ul>
<li><a class="reference internal" href="#">The CoVar Zeitgeist: December, 2025</a><ul>
<li><a class="reference internal" href="#featured">Featured</a></li>
<li><a class="reference internal" href="#llms">LLMs</a></li>
<li><a class="reference internal" href="#novel-architectures">Novel Architectures</a></li>
<li><a class="reference internal" href="#object-detection">Object Detection</a></li>
<li><a class="reference internal" href="#edge-computation">Edge Computation</a></li>
<li><a class="reference internal" href="#testing-evaluation">Testing &amp; Evaluation</a></li>
<li><a class="reference internal" href="#autonomy">Autonomy</a></li>
<li><a class="reference internal" href="#reinforcement-learning">Reinforcement Learning</a></li>
<li><a class="reference internal" href="#statistics">Statistics</a></li>
<li><a class="reference internal" href="#applications">Applications</a></li>
<li><a class="reference internal" href="#covar-seminar">CoVar Seminar</a></li>
</ul>
</li>
</ul>

            </div>
        </div>
    

      <div class="clearer"></div>
    </div>
    <div class="button_nav_wrapper">
        <div class="button_nav">
            <div class="left">
                
                <a href="2026-01.html">
                    <span class="icon">&lt;</span><span>The CoVar Zeitgeist: January, 2026</span></a>
                
            </div>

            <div class="right">
                
                    <a href="2025-11.html"><span>The CoVar Zeitgeist: November, 2025</span><span class="icon">&gt;</span></a>
                
            </div>
        </div>
    </div>


    <div class="footer" role="contentinfo">
        &#169; Copyright 2025, CoVar, LLC.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    </div>

<p id="theme_credit"></p>
  </body>
</html>