
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>The CoVar Zeitgeist: May, 2024 &#8212; The CoVar Zeitgeist 1.0.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic_mod.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Lato" />
    <link rel="stylesheet" type="text/css" href="../_static/pytorch_theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <script src="../_static/js/petite-vue.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The CoVar Zeitgeist: April, 2024" href="2024-04.html" />
    <link rel="prev" title="The CoVar Zeitgeist: June, 2024" href="2024-06.html" /> 
  </head><body data-dark_mode_code_blocks="true">

<div id="top_nav">
    
        <div id="notification_banner" data-banner-hiding="temporary" v-show="!permanentlyHidden">
    <p v-if="visible" id="content">The <a href="https://covar.com/">CoVar</a> Zeitgeist is a curated synopsis of the latest advances in AI/ML research specifically tailored to our mission.</p>
    <a class="close" href="#" @click.prevent="toggleVisible()">[[ visible ? '&#x25B2; HIDE' : '&#x25BC; SHOW BANNER' ]]</a>
</div>

<script>
(function() {
    const topNav = document.querySelector('#top_nav')
    const notificationContent = document.querySelector('#notification_banner p#content').innerText
    const localStorageKey = 'readNotification'
    const bannerHiding = document.querySelector('#notification_banner').dataset['bannerHiding']
    const cssVariableName = '--navbarHeight'
    const rootElement = document.documentElement

    /*************************************************************************/
    // Local storage for remembering if the user has read the notification.

    function checkAlreadyRead() {
        return localStorage.getItem(localStorageKey) == notificationContent
    }

    function setRead() {
        localStorage.setItem(localStorageKey, notificationContent)
    }

    function clearRead() {
        localStorage.removeItem(localStorageKey)
    }

    const alreadyRead = checkAlreadyRead()
    const permanentlyHidden = alreadyRead && bannerHiding == 'permanent'

    /*************************************************************************/
    // Updating a CSS variable so other elements adjust to the nav bar height.

    function updateNavbarHeight() {
        // Only update it if the delta is significant. Otherwise it causes
        // unnecessary browser repaints.
        const documentStyles = getComputedStyle(rootElement)
        // We store the value in REM, so need to convert to pixels
        const currentValue = parseFloat(
            documentStyles.getPropertyValue(cssVariableName)
        ) * parseFloat(documentStyles.fontSize)

        const newValue = topNav.clientHeight

        if (newValue - 5 > currentValue) {
            console.log(`Updating ${cssVariableName} - overlapping`)
            rootElement.style.setProperty(
                cssVariableName, newValue + "px"
            );
        } else if (currentValue - newValue >= 30) {
            console.log(`Updating ${cssVariableName} - gap too large`)
            rootElement.style.setProperty(
                cssVariableName, newValue + "px"
            );
        }
    }

    /*************************************************************************/
    // After loading the page, and resizing the window, recalculate the nav bar
    // height.

    if (!permanentlyHidden) {
        // This height is approximately correct when there's a banner, so
        // shouldn't require any page reflow:
        rootElement.style.setProperty(
            '--navbarHeight', "5.5rem"
        );

        document.addEventListener("DOMContentLoaded", function() {
            updateNavbarHeight()
        });

        var interval = undefined

        window.addEventListener('resize', () => {
            if (interval) {
                clearTimeout(interval)
            }
            interval = setTimeout(() => {
                console.log("Finished resizing")
                updateNavbarHeight()
            }, 100)
        })
    }

    /*************************************************************************/

    PetiteVue.createApp({
        visible: !alreadyRead,
        permanentlyHidden: permanentlyHidden,
        bannerHiding: bannerHiding,
        $delimiters: ['[[', ']]'],
        toggleVisible() {
            this.visible = !this.visible

            if (this.visible) {
                clearRead()
            } else {
                setRead()
            }

            if (!this.visible && bannerHiding == 'permanent') {
                this.permanentlyHidden = true
            }

            // Run this after Vue has had time to update the DOM:
            setTimeout(
                updateNavbarHeight,
                0
            )
        }
    }).mount('#notification_banner')
})()
</script>
    

    <nav>
        
            
        

        <p id="toggle_sidebar">
            <a href="#" title="Toggle sidebar">|||</a>
        </p>
        <h1><a href="../index.html" title="Go to homepage"><img src="../_static/covar_logo_white.png"/></a></h1>

        <a id="mode_toggle" href="#" @click.prevent="handleClick" :title="mode">
    <template v-if="mode == 'light'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_light"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><circle cx="39.311" cy="39.524" r="15.734" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.212,4.901c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901l-0,9.614c-0,2.705 2.196,4.901 4.9,4.901c2.705,0 4.901,-2.196 4.901,-4.901l0,-9.614Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M67.48,18.073c1.913,-1.912 1.913,-5.018 0,-6.931c-1.912,-1.912 -5.018,-1.912 -6.931,0l-6.798,6.799c-1.912,1.912 -1.912,5.018 0,6.931c1.913,1.912 5.018,1.912 6.931,-0l6.798,-6.799Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.728,61.108c1.912,-1.913 1.912,-5.018 -0,-6.931c-1.913,-1.913 -5.019,-1.913 -6.931,-0l-6.799,6.798c-1.912,1.913 -1.912,5.019 0,6.931c1.913,1.913 5.019,1.913 6.931,0l6.799,-6.798Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.682,54.177c-1.913,-1.913 -5.018,-1.913 -6.931,-0c-1.912,1.913 -1.912,5.018 0,6.931l6.798,6.798c1.913,1.913 5.019,1.913 6.931,0c1.913,-1.912 1.913,-5.018 0,-6.931l-6.798,-6.798Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M4.901,34.623c-2.705,0 -4.901,2.196 -4.901,4.901c0,2.705 2.196,4.901 4.901,4.901l9.614,0c2.705,0 4.901,-2.196 4.901,-4.901c0,-2.705 -2.196,-4.901 -4.901,-4.901l-9.614,0Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.212,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901l-0,9.614c-0,2.705 2.196,4.901 4.9,4.901c2.705,-0 4.901,-2.196 4.901,-4.901l0,-9.614Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M18.929,11.142c-1.912,-1.912 -5.018,-1.912 -6.931,0c-1.912,1.913 -1.912,5.019 0,6.931l6.799,6.799c1.912,1.912 5.018,1.912 6.931,-0c1.912,-1.913 1.912,-5.019 -0,-6.931l-6.799,-6.799Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.108,34.623c-2.705,0 -4.901,2.196 -4.901,4.901c-0,2.705 2.196,4.901 4.901,4.901l9.614,0c2.705,0 4.901,-2.196 4.901,-4.901c-0,-2.705 -2.196,-4.901 -4.901,-4.901l-9.614,0Z" style="fill:#fff;"/></g></g></g></svg>
    </template>

    <template v-if="mode == 'dark'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_dark"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><circle cx="39.311" cy="39.524" r="15.734" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.212,14.515c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,0 -4.901,2.196 -4.901,4.901c0,2.705 2.197,4.901 4.901,4.901c2.705,0 4.901,-2.196 4.901,-4.901Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M60.662,24.892c1.902,-1.902 1.902,-4.99 0,-6.892l-0.04,-0.039c-1.901,-1.902 -4.989,-1.902 -6.891,-0c-1.901,1.901 -1.901,4.989 0,6.891l0.04,0.04c1.902,1.901 4.989,1.901 6.891,-0Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.732,61.103c1.91,-1.91 1.91,-5.011 0,-6.921l-0.009,-0.01c-1.91,-1.91 -5.012,-1.91 -6.921,-0c-1.91,1.91 -1.91,5.011 -0,6.921l0.01,0.01c1.909,1.91 5.011,1.91 6.92,-0Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.672,54.167c-1.907,-1.907 -5.004,-1.907 -6.911,0l-0.02,0.02c-1.907,1.907 -1.907,5.004 0,6.911c1.907,1.907 5.004,1.907 6.911,-0l0.02,-0.02c1.907,-1.907 1.907,-5.004 0,-6.911Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M14.52,34.623c-2.702,0 -4.896,2.194 -4.896,4.896l0,0.01c0,2.702 2.194,4.896 4.896,4.896c2.702,0 4.896,-2.194 4.896,-4.896l-0,-0.01c-0,-2.702 -2.194,-4.896 -4.896,-4.896Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.212,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.901,2.196 -4.901,4.901c0,2.704 2.197,4.9 4.901,4.9c2.705,0 4.901,-2.196 4.901,-4.9Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M25.73,17.943c-1.911,-1.911 -5.015,-1.911 -6.926,0l-0.005,0.005c-1.911,1.911 -1.911,5.015 0,6.926c1.911,1.911 5.015,1.911 6.926,0l0.005,-0.005c1.911,-1.911 1.911,-5.014 -0,-6.926Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.098,34.623c-2.699,0 -4.891,2.192 -4.891,4.892l-0,0.019c-0,2.699 2.192,4.891 4.891,4.891c2.7,0 4.892,-2.192 4.892,-4.891l0,-0.019c0,-2.7 -2.192,-4.892 -4.892,-4.892Z" style="fill:#fff;"/></g></g></g></svg>
    </template>

    <template v-if="mode == 'darkest'">
        <svg width="100%" height="100%" viewBox="0 0 79 80" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;"><g id="mode_darkest"><rect id="Bounds" x="0" y="-0" width="78.623" height="79.049" style="fill:none;"/><path d="M39.315,23.791c8.684,-0 15.734,7.05 15.734,15.733c0,8.684 -7.05,15.734 -15.734,15.734c-8.683,0 -15.733,-7.05 -15.733,-15.734c-0,-8.683 7.05,-15.733 15.733,-15.733Zm0,4.737c6.069,0 10.997,4.927 10.997,10.996c-0,6.069 -4.928,10.996 -10.997,10.996c-6.068,0 -10.996,-4.927 -10.996,-10.996c0,-6.069 4.928,-10.996 10.996,-10.996Z" style="fill:#fff;"/><g id="beams"><g id="beam"><path id="beam1" serif:id="beam" d="M44.216,14.515c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,0 -4.9,2.196 -4.9,4.901c-0,2.705 2.196,4.901 4.9,4.901c2.705,0 4.901,-2.196 4.901,-4.901Z" style="fill:#fff;"/></g><g id="beam2" serif:id="beam"><path id="beam3" serif:id="beam" d="M60.666,24.892c1.902,-1.902 1.902,-4.99 0,-6.892l-0.04,-0.039c-1.901,-1.902 -4.989,-1.902 -6.891,-0c-1.901,1.901 -1.901,4.989 0,6.891l0.04,0.04c1.902,1.901 4.99,1.901 6.891,-0Z" style="fill:#fff;"/></g><g id="beam4" serif:id="beam"><path id="beam5" serif:id="beam" d="M25.737,61.103c1.909,-1.91 1.909,-5.011 -0,-6.921l-0.01,-0.01c-1.91,-1.91 -5.011,-1.91 -6.921,-0c-1.91,1.91 -1.91,5.011 -0,6.921l0.01,0.01c1.91,1.91 5.011,1.91 6.921,-0Z" style="fill:#fff;"/></g><g id="beam6" serif:id="beam"><path id="beam7" serif:id="beam" d="M60.676,54.167c-1.907,-1.907 -5.004,-1.907 -6.911,0l-0.02,0.02c-1.907,1.907 -1.907,5.004 0,6.911c1.907,1.907 5.004,1.907 6.911,-0l0.02,-0.02c1.907,-1.907 1.907,-5.004 0,-6.911Z" style="fill:#fff;"/></g><g id="beam8" serif:id="beam"><path id="beam9" serif:id="beam" d="M14.524,34.623c-2.702,0 -4.896,2.194 -4.896,4.896l0,0.01c0,2.702 2.194,4.896 4.896,4.896c2.702,0 4.896,-2.194 4.896,-4.896l0,-0.01c0,-2.702 -2.194,-4.896 -4.896,-4.896Z" style="fill:#fff;"/></g><g id="beam10" serif:id="beam"><path id="beam11" serif:id="beam" d="M44.216,64.534c0,-2.705 -2.196,-4.901 -4.901,-4.901c-2.704,-0 -4.9,2.196 -4.9,4.901c-0,2.704 2.196,4.9 4.9,4.9c2.705,0 4.901,-2.196 4.901,-4.9Z" style="fill:#fff;"/></g><g id="beam12" serif:id="beam"><path id="beam13" serif:id="beam" d="M25.734,17.943c-1.911,-1.911 -5.015,-1.911 -6.926,0l-0.005,0.005c-1.911,1.911 -1.911,5.015 0,6.926c1.911,1.911 5.015,1.911 6.926,0l0.005,-0.005c1.911,-1.911 1.911,-5.014 0,-6.926Z" style="fill:#fff;"/></g><g id="beam14" serif:id="beam"><path id="beam15" serif:id="beam" d="M64.103,34.623c-2.7,0 -4.892,2.192 -4.892,4.892l-0,0.019c-0,2.699 2.192,4.891 4.892,4.891c2.699,0 4.891,-2.192 4.891,-4.891l0,-0.019c0,-2.7 -2.192,-4.892 -4.891,-4.892Z" style="fill:#fff;"/></g></g></g></svg>
    </template>
</a>

<script>
(function() {
    const LOCAL_STORAGE_KEY = 'piccoloThemeMode'

    var initialMode = localStorage.getItem(LOCAL_STORAGE_KEY)

    if (initialMode) {
        // Make sure the value in local storage is valid
        if (['light', 'dark', 'darkest'].indexOf(initialMode) == -1) {
            initialMode = 'light'
            localStorage.setItem(LOCAL_STORAGE_KEY, initialMode)
        }
    } else {
        // Check if the client prefers dark mode
        if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
            initialMode = 'dark'
        } else {
            initialMode = 'light'
        }
        localStorage.setItem(LOCAL_STORAGE_KEY, initialMode)
    }

    document.documentElement.dataset.mode = initialMode

    PetiteVue.createApp({
        'mode': initialMode,
        handleClick() {
            let currentMode = this.mode

            if (currentMode == 'light') {
                this.mode = 'dark'
            } else if (currentMode == 'dark') {
                this.mode = 'darkest'
            } else if (currentMode == 'darkest') {
                this.mode = 'light'
            }

            document.documentElement.dataset.mode = this.mode
            localStorage.setItem(LOCAL_STORAGE_KEY, this.mode)

            console.log(this.mode)
        }
    }).mount('#mode_toggle')
})()
</script>
            <p class="mobile_search_link">
                <a href="../search.html" title="Search">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 65 64" fill-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
                        <path d="M14.873 40.009c-2.315-3.943-3.642-8.532-3.642-13.429C11.231 11.91 23.141 0 37.811 0s26.58 11.91 26.58 26.58-11.91 26.58-26.58 26.58a26.44 26.44 0 0 1-14.277-4.161L9.739 62.794a3.12 3.12 0 0 1-4.413 0L.913 58.382c-1.217-1.218-1.217-3.196 0-4.413l13.96-13.96zM37.811 8.054c10.225 0 18.526 8.301 18.526 18.526s-8.301 18.526-18.526 18.526-18.526-8.301-18.526-18.526S27.586 8.054 37.811 8.054z" fill="#fff" />
                    </svg>
                </a>
            </p>
        

        <div class="searchbox_wrapper">
            
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
    </nav>
</div>

    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption" role="heading"><span class="caption-text">2026</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="2026-02.html">2026-02</a></li>
<li class="toctree-l1"><a class="reference internal" href="2026-01.html">2026-01</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2025</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="2025-12.html">2025-12</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-11.html">2025-11</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-10.html">2025-10</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-09.html">2025-09</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-08.html">2025-08</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-07.html">2025-07</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-06.html">2025-06</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-05.html">2025-05</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-04.html">2025-04</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-03.html">2025-03</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-02.html">2025-02</a></li>
<li class="toctree-l1"><a class="reference internal" href="2025-01.html">2025-01</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2024</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="2024-12.html">2024-12</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-11.html">2024-11</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-10.html">2024-10</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-09.html">2024-09</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-08.html">2024-08</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-07.html">2024-07</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-06.html">2024-06</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2024-05</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-04.html">2024-04</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-03.html">2024-03</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-02.html">2024-02</a></li>
<li class="toctree-l1"><a class="reference internal" href="2024-01.html">2024-01</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">2023</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="2023-12.html">2023-12</a></li>
</ul>

        </div>
      </div>


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="the-covar-zeitgeist-may-2024">
<h1>The CoVar Zeitgeist: May, 2024<a class="headerlink" href="#the-covar-zeitgeist-may-2024" title="Permalink to this heading">¶</a></h1>
<p>A curated list of the latest research in AI.</p>
<section id="featured">
<h2>Featured<a class="headerlink" href="#featured" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2310.03302">MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation</a></dt><dd><p>Can LLMs act as Machine Learning Engineers and conduct effective ML experimentation when presented with a dataset?  This paper investigates, to mixed results.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.01413.pdf">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</a></dt><dd><p>Investigates model collapse, where generative models trained on their own outputs tend to collapse.  Part of the reason this occurs is because new generated data replaces old real data; instead, if old data is supplemented by rather than replaced with new generated data then model collapse does not occur.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.09173.pdf">TransformerFAM: Feedback attention is working memory</a></dt><dd><p>Introduces a feedback loop into the transformer model to allow it to self-attend to its own latent representations.  Authors claim this is like giving a transformer working memory and allows it to process indefinitely long sequences.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.12379.pdf">Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular Videos</a></dt><dd><p>Recovers object meshes from a video of an object.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.03893.pdf">KGExplainer: Towards Exploring Connected Subgraph Explanations for Knowledge Graph Completion</a></dt><dd><p>Proposes a method to explain knowledge graph completions done with knowledge graph embeddings by investigating connected subgraphs.  Makes intuitive sense and seems to improve performance in practice.</p>
</dd>
</dl>
</section>
<section id="llms">
<h2>LLMs<a class="headerlink" href="#llms" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.11794.pdf">Automated Social Science: Language Models as Scientist and Subjects</a></dt><dd><p>This paper has LLMs roleplay and act as human agents in simulated situations to test social science hypotheses in silico.  Finds that LLMs as roleplay agents can reproduce results form the social science literature that they claim not to know when asked directly.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2310.03302">MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation</a></dt><dd><p>Can LLMs act as Machine Learning Engineers and conduct effective ML experimentation when presented with a dataset?  This paper investigates, to mixed results.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.14367.pdf">Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data</a></dt><dd><p>A deep dive into how to optimally fine-tune LLMs in a variety of situations.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.13208.pdf">The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions</a></dt><dd><p>Proposes that LLMs be trained to prioritize some instructions over others, instead of treating all instructions equally.  This can help with alignment concerns.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.07647.pdf">Why do small language models underperform? Studying LM Saturation via the Softmax Bottleneck</a></dt><dd><p>Investigates why smaller LLMs experience performance drops and plateaus during training.  The answer is that the hidden dimension of smaller LLMs is too small to capture the distribution it is targeting and encounters the softmax bottleneck.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.15758">Let’s Think Dot by Dot: Hidden Computation in Transformer Language Models</a></dt><dd><p>Chain-of-thought may be outperforming other methods because it provides LLMs with more computing power rather than because it increases reasoning capabilities.  To test this, the authors give LLMs filler tokens and demonstrate that it can use these like it would Chain-of-Thought, but needs to be trained in a very specific manner.</p>
</dd>
</dl>
</section>
<section id="object-detection">
<h2>Object Detection<a class="headerlink" href="#object-detection" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.04140.pdf">Improving Detection in Aerial Images by Capturing Inter-Object Relationships</a></dt><dd><p>Entities tend to be spatially correlated, but existing overhead ATR methods don’t take this into account.  This paper does so by putting a transformer on top of traditional two-stage detectors to examine regions of interest.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.03595.pdf">DiffDet4SAR: Diffusion-based Aircraft Target Detection Network for SAR Images</a></dt><dd><p>ConvNets/transformers for overhead sensing in SAR are limited by varying target size, spikiness of SAR data, and general noise.  The papers attempts to ameliorate these problems by (1) using a denoising diffusion process and (2) using a scattering feature enhancement to model the SAR data.  Seems to improve results.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.12379.pdf">Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Monocular Videos</a></dt><dd><p>Recovers object meshes from a video of an object.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.01260.pdf">Bridging Remote Sensors with Multisensor Geospatial Foundation Models</a></dt><dd><p>Investigates how to fuse together multiple modalities in remote sensing.  Creates distinct embedding layers for each sensor, inputs all of them into a shared encoder, and decodes on a per-sensor level.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.02659.pdf">A Satellite Band Selection Framework for Amazon Forest Deforestation Detection Task</a></dt><dd><p>Uses the Univariate Marginal Distribution Algorithm (UMDA) to select the optimal Landsat band for overhead monitoring.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.03883.pdf">LiDAR-Guided Cross-Attention Fusion for Hyperspectral Band Selection and Image Classification</a></dt><dd><p>Makes use of LiDAR to select the best hyperspectral bands using self-attention encoders, then uses these for image classification.</p>
</dd>
</dl>
</section>
<section id="autonomy">
<h2>Autonomy<a class="headerlink" href="#autonomy" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.03596.pdf">Laser Learning Environment: A new environment for coordination-critical multi-agent tasks</a></dt><dd><p>Introduces a new environment for multi-agent reinforcement learning.  One problem they encounter and highlight is that the agents can get stuck in a state space.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.08523.pdf">Advancing Forest Fire Prevention: Deep Reinforcement Learning for Effective Firebreak Placement</a></dt><dd><p>Implements deep reinforcement learning on satellite pictures to discover optimal placement for firebreaks in case of forest fires.  We could implement a similar approach to find optimal spots for, e.g., fortifications.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.11458.pdf">Learn to Tour: Operator Design For Solution Feasibility Mapping in Pickup-and-delivery Traveling Salesman Problem</a></dt><dd><p>Uses reinforcement learning for the pickup and delivery traveling salesman problem.  Could be an interesting route-finding algorithm for autonomous vehicles.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/ftp/arxiv/papers/2404/2404.13954.pdf">A survey of air combat behavior modeling using machine learning</a></dt><dd><p>Norwegian Defence researchers analyze how well current reinforcement learning methods are producing en silico agents for simulation of aerial combat.</p>
</dd>
</dl>
</section>
<section id="theory">
<h2>Theory<a class="headerlink" href="#theory" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.01413.pdf">Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data</a></dt><dd><p>Investigates model collapse, where generative models trained on their own outputs tend to collapse.  Part of the reason this occurs is because new generated data replaces old real data; instead, if old data is supplemented by rather than replaced with new generated data then model collapse does not occur.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.06549.pdf">Variational Stochastic Gradient Descent for Deep Neural Networks</a></dt><dd><p>Proposes a new method for gradient descent, Variational Stochastic Gradient Descent, which outperforms both ADAM and regular SGD on the image classification examples in the paper. VSGD is a generalization of regular SGD and ADAM.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.08819.pdf">The Illusion of State in State-Space Models</a></dt><dd><p>Finds that state-space models with finite layers have no advantage over transformers in state-space tracking: SSMs are limited at keeping track of entities in narratives, playing chess, or evaluating code.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.09173.pdf">TransformerFAM: Feedback attention is working memory</a></dt><dd><p>Introduces a feedback loop into the transformer model to allow it to self-attend to its own latent representations.  Authors claim this is like giving a transformer working memory and allows it to process indefinitely long sequences.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.07143.pdf">Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</a></dt><dd><p>Uses compressive memory to store input tokens as parameters which can be updated.  This, theoretically, enables handling and processing of infinite input data.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.17563">An exactly solvable model for emergence and scaling laws</a></dt><dd><p>Explicitly models where scaling begins for neural net training in terms of training time, training data, and model size in two-layer NNs.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.04865.pdf">On the Learnability of Out-of-distribution Detection</a></dt><dd><p>Investigates and proves when OOD detection is theoretically impossible and when it’s possible.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.10207.pdf">HELLINGER-UCB: A NOVEL ALGORITHM FOR STOCHASTIC MULTI-ARMED BANDIT PROBLEM AND COLD START PROBLEM IN RECOMMENDER SYSTEM</a></dt><dd><p>Proposes new multi-armed bandit algorithm with applications to cold-start scenarios in recommender systems.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.16746">Estimating the Number of Components in Finite Mixture Models via Variational Approximation</a></dt><dd><p>ELBO-based method to try to estimate number of components in mixture models.</p>
</dd>
</dl>
</section>
<section id="computational-efficiency">
<h2>Computational Efficiency<a class="headerlink" href="#computational-efficiency" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.07188.pdf">GCV-Turbo: End-to-end Acceleration of GNN-based Computer Vision Tasks on FPGA</a></dt><dd><p>From DEVCOM Army Research Office.  Investigates how to pu CNNs and GNNs for computer-vision tasks on FPGAs.</p>
</dd>
</dl>
</section>
<section id="knowledge-graphs">
<h2>Knowledge Graphs<a class="headerlink" href="#knowledge-graphs" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.02127.pdf">FLawN-T5: An Empirical Examination of Effective Instruction Tuning Data Mixtures for Legal Reasoning</a></dt><dd><p>Claims that legal reasoners tend to have poor performances because there isn’t a proper legal reasoning dataset.  This paper introduces one, finetunes a model, and demonstrates much better performance.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.02778.pdf">Chain event graphs for assessing activity-level propositions in forensic science in relation to drug traces on banknotes</a></dt><dd><p>Implements legal reasoning via turning arguments into graphical models, assigning probabilities to edges, and turning the crank.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.03893.pdf">KGExplainer: Towards Exploring Connected Subgraph Explanations for Knowledge Graph Completion</a></dt><dd><p>Proposes a method to explain knowledge graph completions done with knowledge graph embeddings by investigating connected subgraphs.</p>
</dd>
</dl>
</section>
<section id="applications">
<h2>Applications<a class="headerlink" href="#applications" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.01268.pdf">Mapping the Increasing Use of LLMs in Scientific Papers</a></dt><dd><p>Trawls arXiv to investigate out how much of it is LLM generated, looking at near a million papers.  Finds that 17.5 percent of CS papers are LLM-generated.</p>
</dd>
</dl>
</section>
<section id="new-models">
<h2>New Models<a class="headerlink" href="#new-models" title="Permalink to this heading">¶</a></h2>
<dl class="simple">
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.07839.pdf">RecurrentGemma: Moving Past Transformers for Efficient Open Language Models</a></dt><dd><p>Deepmind proposes a new LLM.  Doesn’t use global attention, but instead uses local attention and linear recurrences.</p>
</dd>
<dt><a class="reference external" href="https://publications.reka.ai/reka-core-tech-report.pdf">Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models</a></dt><dd><p>A multimodal foundation model.  Does not seem to be open source.</p>
</dd>
<dt><a class="reference external" href="https://llama.meta.com/llama3/">Llama 3</a></dt><dd><p>Meta’s new LLM.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.14219.pdf">Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</a></dt><dd><p>New LLM from Microsoft that is small enough to run natively on an iPhone 14 but achieves comparable results to GPT-4.  Most of the penalty it pays for its small size takes the form of less factual knowledge.</p>
</dd>
<dt><a class="reference external" href="https://arxiv.org/pdf/2404.18416">Capabilities of Gemini Models in Medicine</a></dt><dd><p>Google release Med-Gemini, which is Gemini but fine-tuned to the medical domain.</p>
</dd>
</dl>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
    
        <div id="show_right_sidebar">
            <p><a class="toggle_right_sidebar" href="#"><span class="icon">&lt;</span><span>Page contents</span></a></p>
        </div>

        <div id="right_sidebar">
            <p><a class="toggle_right_sidebar" href="#"><span class="icon">&gt;</span><span>Page contents:</span></a></p>
            <div class="page_toc">
                <ul>
<li><a class="reference internal" href="#">The CoVar Zeitgeist: May, 2024</a><ul>
<li><a class="reference internal" href="#featured">Featured</a></li>
<li><a class="reference internal" href="#llms">LLMs</a></li>
<li><a class="reference internal" href="#object-detection">Object Detection</a></li>
<li><a class="reference internal" href="#autonomy">Autonomy</a></li>
<li><a class="reference internal" href="#theory">Theory</a></li>
<li><a class="reference internal" href="#computational-efficiency">Computational Efficiency</a></li>
<li><a class="reference internal" href="#knowledge-graphs">Knowledge Graphs</a></li>
<li><a class="reference internal" href="#applications">Applications</a></li>
<li><a class="reference internal" href="#new-models">New Models</a></li>
</ul>
</li>
</ul>

            </div>
        </div>
    

      <div class="clearer"></div>
    </div>
    <div class="button_nav_wrapper">
        <div class="button_nav">
            <div class="left">
                
                <a href="2024-06.html">
                    <span class="icon">&lt;</span><span>The CoVar Zeitgeist: June, 2024</span></a>
                
            </div>

            <div class="right">
                
                    <a href="2024-04.html"><span>The CoVar Zeitgeist: April, 2024</span><span class="icon">&gt;</span></a>
                
            </div>
        </div>
    </div>


    <div class="footer" role="contentinfo">
        &#169; Copyright 2025, CoVar, LLC.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    </div>

<p id="theme_credit"></p>
  </body>
</html>